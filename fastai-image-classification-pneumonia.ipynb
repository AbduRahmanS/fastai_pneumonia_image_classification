{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome to this notebook on chest X-ray image classification using the fastai library. This notebook aims to provide a step-by-step guide on how to build and train a deep learning model to classify chest X-ray images into three categories: normal, bacterial pneumonia, and viral pneumonia. Accurate classification of chest X-ray images is crucial for early diagnosis and treatment of various respiratory diseases.\n\nIn this notebook, we will use the fastai library, which is built on top of PyTorch, to construct our deep learning model. We will start by exploring the data and then pre-processing it using various data augmentation techniques to improve the performance of our model. We will then construct a deep learning model using a pre-trained convolutional neural network (CNN) and fine-tune it on our dataset. Finally, we will evaluate the performance of our model and visualize the results using a confusion matrix.\n\nThis notebook assumes that you have some basic knowledge of deep learning and the Python programming language. However, we will provide explanations and examples for each step to make it accessible to beginners. So, let's get started!","metadata":{}},{"cell_type":"markdown","source":"## **Set Up**\nLet's import all necessary libraries from Fastai, a popular open-source deep learning library. Fastai has been developed on top of PyTorch, another popular deep learning library, to simplify and streamline the process of building and training deep learning models.","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade fastai\nfrom fastai.vision.all import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Loading the data**\nFirst, we'll load the data from our Kaggle dataset using the Path and labeller functions from the Fastai library. We'll use the labeller function to label each image as either normal, bacterial pneumonia, or viral pneumonia based on the file path.","metadata":{}},{"cell_type":"code","source":"path = Path('/kaggle/input/chest-xray-pneumonia/chest_xray/')\ndef labeller(file_path):\n    if 'virus' in file_path.name:\n        return 'viral'\n    elif 'bacteria' in file_path.name:\n        return 'bacterial'\n    else:\n        return 'normal'\n\n\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Creating the DataBlock**\nNext, we'll create a DataBlock object to prepare the data for our neural network, this will be used to load and transform the images:\n\n* blocks: a tuple containing the types of data blocks we will be working with, in this case an ImageBlock for our images and a CategoryBlock for our labels\n* get_items: a function that gets the image files from the path defined in the previous cell\n* splitter: a RandomSplitter that randomly splits the data into training and validation sets with a 20% validation set size and a random seed of 42\n* batch_tfms: a list of data augmentations that will be applied to our images during training, in this case including random flips, rotations, and zooms, as well as normalization based on the ImageNet statistics.\n* get_y: the labeller function defined in the previous cell that will be used to label the images.\n* item_tfms: a resizing transformation that will resize all images to 128x128 pixels.","metadata":{}},{"cell_type":"code","source":"tfms = aug_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1)\n\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter= RandomSplitter(valid_pct=0.2, seed=42),\n    batch_tfms=[*tfms, Normalize.from_stats(*imagenet_stats)],\n    get_y=labeller,\n    item_tfms=Resize(128))\n\ndls = dblock.dataloaders(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualize and verify**\nNow, let's visualize the images and verify that they have been loaded correctly. The one_batch() function returns a mini-batch of size bs (batch size), which is by default 64. The loaded images are then displayed using the show_batch() function, which takes the loaded batch as input and display a grid of images.","metadata":{}},{"cell_type":"code","source":"batch = dls.train.one_batch()\ndls.train.show_batch(b=batch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training the Model**\nAfter setting up our data with the appropriate transformations, we can now proceed with training our model. we will fist initialize our model using the vision_learner function, specify the architecture we want to use (resnet34) and the metrics we want to monitor during training (accuracy and error_rate).\n\nNow, we will use the fine_tune method to fine-tune the pre-trained ResNet34 model on our pneumonia chest X-ray dataset. Fine-tuning involves training only the last few layers of the model, which are specific to our classification task, while keeping the earlier layers frozen. This approach allows us to leverage the pre-trained weights of the model to improve its performance on our specific task, while avoiding overfitting on our relatively small dataset.\n\nWe then set an early stopping callback fuinction, which monitors the validation loss and stops the training if there is no improvement in the validation loss after a certain number of epochs (patience=2 in this case).\n\nDuring training, the loss and accuracy are displayed for each epoch, along with the duration of the epoch. Once training is complete, the model is saved to disk for future use.","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet34, metrics=[accuracy, error_rate], loss_func=nn.CrossEntropyLoss())\nlearn.fine_tune(10, cbs=[EarlyStoppingCallback(patience=2)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Evaluating the Model**\nFinally, we'll evaluate the performance of our neural network by creating a confusion matrix using the ClassificationInterpretation function.\nWe can visualize the model's performance on the validation set. This allows us to see how well the model is able to classify images from each class and can help identify areas where the model is struggling.","metadata":{}},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}